import asyncio
from openai import AsyncOpenAI
from datetime import datetime

# === é…ç½® ===
API_BASE_URL = "https://openrouter.ai/api/v1/"  # ä½ çš„ç§æœ‰åŒ–æœåŠ¡åœ°å€
API_KEY = "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"                        # ä½ çš„ API Key

# === åˆå§‹åŒ–å®¢æˆ·ç«¯ ===
client = AsyncOpenAI(
    base_url=API_BASE_URL,
    api_key=API_KEY
)

# === å®šä¹‰ä¸€ä¸ª MCP é£æ ¼çš„å·¥å…· ===
async def get_time_tool():
    """è·å–å½“å‰æ—¶é—´"""
    return {"time": datetime.now().isoformat()}

TOOLS = {
    "get_time": get_time_tool
}

# === è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨ ===
async def choose_model():
    print("ğŸ” æ­£åœ¨è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨...")
    models = await client.models.list()
    available_models = [m.id for m in models.data]

    if not available_models:
        print("âŒ æ²¡æœ‰å‘ç°å¯ç”¨æ¨¡å‹ï¼Œè¯·æ£€æŸ¥ API åœ°å€å’Œ Keyï¼")
        return None

    print("\nâœ… å¯ç”¨æ¨¡å‹åˆ—è¡¨ï¼š")
    for i, m in enumerate(available_models, start=1):
        print(f"  {i}. {m}")

    # é€‰æ‹©æ¨¡å‹
    choice = input("\nè¯·é€‰æ‹©æ¨¡å‹ç¼–å·ï¼ˆé»˜è®¤ 1ï¼‰: ").strip()
    if choice.isdigit() and 1 <= int(choice) <= len(available_models):
        return available_models[int(choice) - 1]
    else:
        print(f"é»˜è®¤é€‰æ‹©ç¬¬ 1 ä¸ªæ¨¡å‹ï¼š{available_models[0]}")
        return available_models[0]

# === æ ¸å¿ƒæ™ºèƒ½ä½“ ===
# å¯¹è¯å†å²
conversation_history = [
    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„ AI åŠ©æ‰‹ï¼Œå¯ä»¥èŠå¤©å›ç­”é—®é¢˜ã€‚"}
]

# å¸¸è§æ¨¡å‹ä¸Šä¸‹æ–‡é•¿åº¦ï¼ˆä¹Ÿå¯ä»¥æ ¹æ®å…·ä½“æ¨¡å‹é…ç½®ï¼‰
MODEL_CONTEXT_SIZE = {
    "gpt-4o-mini": 128000,  # GPT-4o-mini æ”¯æŒ 128k
    "gpt-4o": 128000,
    "gpt-3.5-turbo": 16384
}


async def simple_agent(model_name: str, user_input: str):
    # ä¿å­˜ç”¨æˆ·è¾“å…¥
    conversation_history.append({"role": "user", "content": user_input})

    # è°ƒç”¨ API
    response = await client.chat.completions.create(
        model=model_name,
        messages=conversation_history
    )

    # AI å›å¤
    ai_reply = response.choices[0].message.content

    # ä¿å­˜ AI å›å¤
    conversation_history.append({"role": "assistant", "content": ai_reply})

    # è·å– token ä½¿ç”¨æƒ…å†µ
    usage = response.usage  # e.g. {'prompt_tokens': xxx, 'completion_tokens': xxx, 'total_tokens': xxx}

    # è®¡ç®—å‰©ä½™ token
    max_tokens = MODEL_CONTEXT_SIZE.get(model_name, 4096)  # é»˜è®¤ 4k
    used_tokens = usage.total_tokens
    remaining_tokens = max_tokens - used_tokens

    return ai_reply, remaining_tokens

# === è¿è¡Œå…¥å£ ===
async def main():
    # å…ˆåˆ—å‡ºå¯ç”¨æ¨¡å‹å¹¶é€‰æ‹©
    model_name = await choose_model()
    if not model_name:
        return

    print(f"\nğŸ¤– æ™ºèƒ½ä½“å·²å¯åŠ¨ï¼ï¼ˆä½¿ç”¨æ¨¡å‹ï¼š{model_name}ï¼‰è¾“å…¥é—®é¢˜ï¼ˆq é€€å‡ºï¼‰\n")

    while True:
        user_input = input("ä½ ï¼š")
        if user_input.lower() in ["q", "quit", "exit"]:
            break
        answer = await simple_agent(model_name, user_input)
        print("æ™ºèƒ½ä½“ï¼š", answer)

if __name__ == "__main__":
    asyncio.run(main())
